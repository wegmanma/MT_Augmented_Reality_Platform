%!TEX root = ../doc.tex
\chapter{Conclusion}
\label{sec:Conclusion}
The thesis shows that extracting rotation and translation speed from a ToF camera on a frame-by-frame basis works. The reconstruction of the three-dimensional scene from the depth image and SIFT feature points and running up to 512 parallel singular value transforms on brute-forced matches allows finding a good rotation and translation transform. This first step of the three-dimensional RANSAC algorithm enables the system to improve the matching quality by over a factor of two, compared to the brute-force matcher. Applying the singular value transform to each improved match results in an optimal rigid motion transform.\\
The noise of the ToF camera was a significant struggle during this thesis. The noise of the grayscale image causes the extracted SIFT features to jitter, even when the camera is stationary. The noise of the depth information increases the error on the three-dimensional scene reconstruction that forces the RANSAC algorithm to run with loose constraints. These loose constraints allow the RANSAC algorithm to falsely match features only because they are close enough, which induces an error on the rotation and translation estimation. This error again causes the motion data to be noisy.\\
The low framerate of the ToF camera and the processing pipeline is a problem for the Kalman filter, which cannot run at higher speeds. The frame-by-frame translation and rotation information is an average of the motion between the frames, not the velocity at the current frame's time. The low sampling rate requires a downsampling of the IMU data, which induces problems with the gravity compensation.\\ 
The system relies on finding SIFT features on its grayscale image – the algorithm will possibly not find enough features in an empty room.


\section{Possible improvement}
\label{sec:improvement}
A system that estimates the position directly based on visual key points is required to avoid drift on the rigid motion. A visual key point might be a specific cloud of SIFT features or an object classified by an ML algorithm.\\
The system would need to detect new key points, store them in a list, store the position and maybe even improve its position information when new data is available. Estimating the camera's position becomes possible from the external objects' position.\\
The position estimation from an image is valid for the moment where the frame got recorded – unlike the velocity, which is an average between two images. Therefore, the position estimation is not required to run at a high frame rate.\\
A different sensor fusion approach, which allows the IMU to run at its sampling rate without requiring a cumulative sum, would improve the position estimation. The orientation of gravity could be estimated at any point and could correct every single accelerometer measurement.
 

\section{Outlook}
\label{sec:outlook}
Augmented Reality is a vast field with various problems that need to be solved. The moment motion tracking works reliably, it enables multiple applications. Increasing the frame rate and accuracy with a better ToF sensor, as currently investigated by the Institute of Signal Processing and Wireless Communications of ZHAW, might enable the system for other topics. Motion tracking by a ToF camera might be implemented in an autonomous driving platform, with a custom-tailored Kalman filter that takes the wheels and steering into account.\\ 
Developing specialized hardware would be a larger project, as this involves many technologies, like optics, eye tracking, translucent displays and a portable processing platform.\\
Projecting outwards, the author expects Augmented Reality goggles for end consumers to hit the market within the following years, possibly having a similar impact as the smartphone once had. 
